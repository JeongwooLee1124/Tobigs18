{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1DbkY70-hcB"
      },
      "source": [
        "# CNNbasic Assignment#2\n",
        "\n",
        "# AlexNet 구현\n",
        "\n",
        "모델 구현 후 summary로 전체 모델 구조 출력과 주석으로 간단한 설명을 달아주시면 됩니다.\n",
        "\n",
        "프레임워크는 자유이고, 기본 tensforflow와 pytorch tutorial 사이트를 아래에 첨부해 드립니다.\n",
        "\n",
        "이 외 각 프레임워크 별 summary 등 추가적인 사용 방법은 구글링으로 찾아주세요!-!\n",
        "\n",
        "- Tensorflow Tutorial: https://www.tensorflow.org/tutorials?hl=ko\n",
        "\n",
        "- Pytorch Tutorial: https://tutorials.pytorch.kr/\n",
        "\n",
        "![image-2.png](attachment:image-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구조\n",
        "* 5개의 Convolution layer와 3개의 FC layer\n",
        "* Batchnorm 추가\n",
        "* Conv1(ReLU) -> Pool1 -> Batchnorm -> Conv2(ReLU) -> Pool2 -> Batchnorm -> Conv3(ReLU) -> Conv4(ReLU) -> Conv5(ReLU) -> Pool3 -> (Flatten) FC1(ReLU) -> FC2(ReLU) -> FC3(->SOFTMAX) "
      ],
      "metadata": {
        "id": "PWBm2hvgtzKD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yGHLrFU8JkW"
      },
      "source": [
        "## Tensorflow(keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68kj2zUP80f0",
        "outputId": "39f9a0cc-f7b9-4152-ac3e-da169434b5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 27, 27, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 27, 27, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              37752832  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,379,752\n",
            "Trainable params: 62,379,048\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "n_classes = 1000 # class 개수\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "############## Add Layer ##############\n",
        "\n",
        "# convolution layer1\n",
        "model.add(Conv2D(96,(11,11), strides = 4, padding = 'valid', activation = 'relu',input_shape=(227,227,3)))\n",
        "model.add(MaxPooling2D((3,3), strides = (2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# convolution layer2\n",
        "model.add(Conv2D(256,(5,5),strides = 1, padding = 'same', activation = 'relu', input_shape=(27,27,96)))\n",
        "model.add(MaxPooling2D((3,3), strides = (2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# convolution layer3\n",
        "model.add(Conv2D(384,(3,3),strides = 1, padding = 'same',  activation = 'relu', input_shape=(13,13,256)))\n",
        "\n",
        "# convolution layer4\n",
        "model.add(Conv2D(384,(3,3),strides = 1, padding = 'same', activation = 'relu', input_shape=(13,13,384)))\n",
        "\n",
        "# convolution layer5\n",
        "model.add(Conv2D(256,(3,3),strides = 1, padding = 'same',  activation = 'relu', input_shape=(13,13,384)))\n",
        "model.add(MaxPooling2D((3,3), strides = (2,2)))\n",
        "\n",
        "#fully-connected layer1\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "\n",
        "#fully-connected layer2\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "\n",
        "#fully-connected layer3\n",
        "model.add(Dense(1000, activation='softmax'))\n",
        "\n",
        "#######################################\n",
        "\n",
        "# keras summary\n",
        "model.summary() # summary code 추가"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch"
      ],
      "metadata": {
        "id": "G0epFGh7RyVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPXCVbu799Rq",
        "outputId": "b50d0711-b5a0-4f96-c7c6-e966ea51d54a",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
            "       BatchNorm2d-4           [-1, 96, 27, 27]             192\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-6          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-7          [-1, 256, 13, 13]               0\n",
            "       BatchNorm2d-8          [-1, 256, 13, 13]             512\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-12          [-1, 384, 13, 13]               0\n",
            "           Conv2d-13          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-14          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-15            [-1, 256, 6, 6]               0\n",
            "          Flatten-16                 [-1, 9216]               0\n",
            "          Dropout-17                 [-1, 9216]               0\n",
            "           Linear-18                 [-1, 4096]      37,752,832\n",
            "             ReLU-19                 [-1, 4096]               0\n",
            "          Dropout-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 4096]      16,781,312\n",
            "             ReLU-22                 [-1, 4096]               0\n",
            "           Linear-23                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 62,379,048\n",
            "Trainable params: 62,379,048\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 12.02\n",
            "Params size (MB): 237.96\n",
            "Estimated Total Size (MB): 250.57\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes = 1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        \n",
        "        ############## Add Layer ##############\n",
        "        # convolution layer1\n",
        "        self.conv1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size = 11, stride = 4, padding = 0),\n",
        "          # input size : 3 * 227 * 227\n",
        "          # input size 정의 : (C, H, W)\n",
        "          # I'(Size of output image ) = (I-F+2P)/S + 1 = (227-11)/4 + 1 = 55\n",
        "          # 96 * 55 * 55 feature map 생성\n",
        "          nn.ReLU(), # 96 * 55 * 55 유지\n",
        "          nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "          # 55 -> (55-3)/2 + 1 = 27\n",
        "          # 96x27x27 feature map 생성\n",
        "          nn.BatchNorm2d(96)) # 96 * 27 * 27 유지\n",
        "        \n",
        "        # convolution layer2\n",
        "        self.conv2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 96, out_channels = 256, kernel_size = 5, stride = 1, padding = 2),\n",
        "          # input size : 96 * 27 * 27\n",
        "          # I' = (27-5+2*2)/1 + 1 = 27\n",
        "          # 256 * 27 * 27 feature map 생성\n",
        "          nn.ReLU(),  # 256 * 27 * 27 유지\n",
        "          nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
        "          # 13 -> (27-3)/2 + 1 = 13\n",
        "          # 256 * 13 * 13 feature map 생성\n",
        "          nn.BatchNorm2d(256)) # 256 * 13 * 13 유지\n",
        "        \n",
        "        # convolution layer3\n",
        "        self.conv3 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 256, out_channels = 384, kernel_size = 3, stride = 1, padding = 1),\n",
        "          # 256 * 13 * 13\n",
        "          # I' = (13-3+2*1)/1 + 1 = 13\n",
        "          # 384 * 13 * 13 feature map 생성\n",
        "          nn.ReLU()) # 384 * 13 * 13 유지\n",
        "        \n",
        "        # convolution layer4\n",
        "        self.conv4 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 384, out_channels = 384, kernel_size = 3, stride = 1, padding = 1),\n",
        "          # 384 * 13 * 13\n",
        "          # I' = (13-3+2*1)/1 + 1 = 13\n",
        "          # 384 * 13 * 13 feature map 생성\n",
        "          nn.ReLU()) # 384 * 13 * 13 유지\n",
        "        \n",
        "        # convolution layer5\n",
        "        self.conv5 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 384, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
        "          # 384 * 13 * 13\n",
        "          # I' = (13-3+2*1)/1 + 1 = 13\n",
        "          # 384 * 13 * 13 feature map 생성\n",
        "          nn.ReLU(), # 384 * 13 * 13 유지\n",
        "          nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "          # 6 -> (13-3)/2 + 1 = 6\n",
        "          # 256 * 6 * 6 feature map 생성\n",
        "        \n",
        "        # fully-connected layer1\n",
        "        self.fc1 = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(9216, 4096),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # fully-connected layer2\n",
        "        self.fc2 = nn.Sequential(\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(4096, 4096),\n",
        "          nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # fully-connected layer3\n",
        "        self.fc3 = nn.Sequential(\n",
        "          nn.Linear(4096, n_classes)\n",
        "        )    \n",
        "        #######################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        ############## Add Layer ##############\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = F.log_softmax(out, dim=1) \n",
        "        # log_softmax\n",
        "        # 소프트맥스에 log함수를 취한 것으로 softmax 함수의 Vanishing Gradients(기울기 손실) 문제를 보완함\n",
        "        #######################################\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "# pytorch summary\n",
        "model = AlexNet().to(\"cuda\")\n",
        "summary(model, (3, 227, 227)) # summary code 추가"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HzE5HCjYNHly"
      },
      "execution_count": 2,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}